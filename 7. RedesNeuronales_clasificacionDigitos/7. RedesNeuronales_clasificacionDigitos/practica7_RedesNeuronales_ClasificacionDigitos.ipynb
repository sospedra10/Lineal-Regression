{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c37fe422b18d696f22bb90525195124a",
     "grade": false,
     "grade_id": "cell-476efbc31e49e36c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Aprendizaje Formal\n",
    "\n",
    "## Práctica 7: Redes neuronales y clasificación de dígitos\n",
    "\n",
    "En esta práctica vamos a tratar con el problema de reconocimiento de dígitos para lo cual implementaremos una red neuronal, con la propagación hacia adelante y hacia atrás. Además, implementaremos las versiones con y sin regularización de la función de coste y la inicialización aleatoria de los pesos. Finalmente, utilizaremos la red para realizar predicciones.\n",
    "\n",
    "## Índice de la práctica\n",
    "\n",
    "- [Lectura y visualización de datos](#Lectura-y-visualización-de-datos)\n",
    "- [Implementación de una Red Neuronal Multicapa](#Implementación-de-una-Red-Neuronal-Multicapa)\n",
    "- [Propagación hacia adelante (feed-forward)](#Propagación-hacia-adelante---feed-forward)\n",
    "    - [Función de coste](#Función-de-coste)\n",
    "    - [Función de coste con regularización](#Función-de-coste-con-regularización)\n",
    "    - [Propagación hacia atrás (backpropagation)](#Propagación-hacia-atrás---backpropagation )\n",
    "    - [Propagación hacia atrás (backpropagation) con regularización](#Propagación-hacia-atrás---backpropagation---con-regularización)\n",
    "- [Entrenamiento de la red y clasificación](#Entrenamiento-de-la-red-y-clasificación)\n",
    "- [Tarea opcional](#Tarea-opcional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c30b7f1e5a3b62ff65f88f4e46245ffb",
     "grade": false,
     "grade_id": "cell-70812eca49f2cc7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Lectura y visualización de datos\n",
    "\n",
    "El conjunto de datos está disponible en el fichero `ex7data` que como siempre leeremos con `loadtxt` (delimitado por comas). El conjunto de datos tiene 5000 ejemplos. La última columna contiene la clase (los dígitos de 0 a 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "48d977db2495cbdbb1a269b947497725",
     "grade": false,
     "grade_id": "cell-9d0db22a4f8bfcab",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from test_helper import Test\n",
    "\n",
    "\n",
    "# Lee los datos y guárdalos en data\n",
    "data = np.loadtxt('ex7data.txt', delimiter=',')\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1].reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a39daeb19885e25ed792aa3cbd5ba50f",
     "grade": false,
     "grade_id": "cell-0df64d79afc706cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para comprender mejor el problema con el que tratamos, vamos a comenzar mostrando los ejemplos que tenemos. Cada ejemplo está formado por 400 características, que son realmente las intensidades de cada píxel de una imagen de 20x20. Vamos a comprobar que esto es así mostrando diez ejemplos aleatorios (puedes ejecutar varias veces el código para ver diferentes ejemplos). En el título, aparece la clase real del ejemplo en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "\n",
    "for degree in range(9):\n",
    "    plt.subplot(191+degree)\n",
    "    index = np.random.randint(0, X.shape[0])\n",
    "    img = X[index, :].reshape(20, 20, order='F')\n",
    "    plt.imshow(img, cmap=plt.cm.gray)\n",
    "    plt.title(y[index])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "862f034b12c5cd69a731c3100c719bfd",
     "grade": false,
     "grade_id": "cell-bd422c8ea04c2d4c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "¿Seremos capaces de entrenar una red que pueda distinguir el dígito que aparece en la imagen? Lo veremos a lo largo de la práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d94160cbfbb840ebed57ed055791f6a",
     "grade": false,
     "grade_id": "cell-67121f9abe49b40d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Implementación de una Red Neuronal Multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5522e6cf891d365b76216c54c7834057",
     "grade": false,
     "grade_id": "cell-b37b12e0aa632694",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Como hemos visto en teoría, para trabajar con problemas multi-clase con redes neuronales necesitamos transformar la salida que es un solo valor (la clase) a un vector de 0s y 1s, en donde el 1 en la posición correspondiente nos indique a qué clase pertenece el ejemplo. Esto es necesario ya que vamos a tener una neurona de salida para cada una de las clases.\n",
    "\n",
    "Para lograr esta transformación vamos a usar el método OneHotEncoder de scikit, que hace precísamente esa tarea. One-hot enconding convierte una etiqueta de clase $n$ (de entre $k$ clases) en un vector de longitud $k$ donde el índice $n$ está \"hot\" (activado, es decir, a 1), mientras que el resto están a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "83825254a3be6a35bb2d221d0e6316a3",
     "grade": false,
     "grade_id": "cell-117facd4b78f3b97",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n",
      "[0.] [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# Aplica el fit_transform de scikit a y para obtener el nuevo y_onehot\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "print(y_onehot.shape)\n",
    "print(y[0], y_onehot[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acd350025555ef85f445fb7f266f9a54",
     "grade": true,
     "grade_id": "cell-b1de80f014675282",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(list(y_onehot[0,:]), [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], 'One-hot encoding incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "83acb2d9447531c3eb473b7acda8fa06",
     "grade": false,
     "grade_id": "cell-82335ea2d56a0d82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La red neuronal que vamos a construir para este ejercicio tiene tantas neuronas de entrada como características tienen nuestros ejemplos (400 + la unidad de bias). La capa oculta tendrá 25 neuronas (26 con el bias), y la capa de salida tendrá 10 neuronas, que cada una de ellas corresponde a una de las clases. \n",
    "\n",
    "Lo primero que debemos haces es implementar la función de coste para evaluar el coste para un conjunto de parámetros dado. Para ello, primero necesitamos aplicar la propagación hacia adelante, que nos de la salida para cada ejemplo de entrada.\n",
    "\n",
    "Vamos por pasos. Comenzamos implementando la función sigmoide.\n",
    "\n",
    "$$ g(z) = \\frac{1}{1+e^{-z}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "522cfb37ffc81ba643dc903118b1ecd2",
     "grade": false,
     "grade_id": "cell-5a65cf54911a625d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "253427f7266bd0e945c3183bcde282e5",
     "grade": false,
     "grade_id": "cell-bae6c37619ac7bdb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Propagación hacia adelante - feed-forward\n",
    "A continuación, vamos a calcular la propagación hacia adelante. Para ello, recibimos la matriz con los datos $X$ y las dos matrices de pesos $\\Theta^{(1)}$ y $\\Theta^{(2)}$ (los pesos entre la capa de entrada y la capa oculta y los pesos entre la capa oculta y la de salida, respectivamente).\n",
    "\n",
    "Debemos seguir los siguientes pasos:\n",
    "1. Añadir el bias a todos los ejemplos de $X$ (la primera columna de 1s). Obtenemos $a^{(1)}$\n",
    "2. Obtenemos $z^{(2)}=a^{(1)}·\\Theta^{(1)}$\n",
    "3. Obtenemos $a^{(2)}$ a partir de $z^{(2)}$ aplicando la sigmoide ($a^{(2)}=g(z^{(2)})$  y le añadimos el bias (primera columna de 1s).\n",
    "4. Obtenemos $z^{(3)}=a^{(2)}·\\Theta^{(2)}$\n",
    "5. Obtenemos $h_{\\Theta}(X)=g(z^{(3)})$\n",
    "\n",
    "En $h_{\\Theta}(X)$ tenemos por tanto una matriz de $5000\\times 10$ con las salidas de las 10 neuronas para cada uno de los 5000 ejemplos. La siguiente figura clarifica el proceso.\n",
    "![Feed Forward](img_forward.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1b77509b64da76f3adfa481412c49845",
     "grade": false,
     "grade_id": "cell-4e4237bb30dcb4cc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Añadimos la columna de unos a X para obtener a1\n",
    "    a1 = np.hstack((np.ones((m, 1)), X))\n",
    "    # Calculamos z2 -> ten en cuenta que a1 tiene tantas filas como ejemplos y columnas como atributos + 1\n",
    "    # Por otro lado, theta1 tiene tantas filas como neuronas en la capa oculta y columnas como atributos + 1\n",
    "    z2 = np.dot(a1, theta1.T)\n",
    "    # Añadimos la columna de unos a la sigmoide de z2 (que es a2) para obtener el a2 definitivo\n",
    "    a2 = np.hstack((np.ones((z2.shape[0], 1)), sigmoid(z2)))\n",
    "    # Calculamos z3\n",
    "    z3 = np.dot(a2, theta2.T)\n",
    "    # Obtenemos la salida final en h\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d0058be996849f40c2c567871b209f3",
     "grade": false,
     "grade_id": "cell-35afd1753339e852",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Función de coste "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0ee9119b381f01cd772104d63fc44bb",
     "grade": false,
     "grade_id": "cell-17344543896d1dc2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Con la propagación hacia adelante, ya podemos calcular la función de coste:\n",
    "$$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\big[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\big]$$\n",
    "\n",
    "Aquí debemos tener cuidado porque para utilizar la función `minimize` de scipy, los parámetros $\\Theta^{(1)}$ y $\\Theta^{(2)}$ nos llegan en un único parámetro `params` y debemos desempaquetarlas. Además, hay que tener en cuenta que $y$ es una matriz de ejemplos x número de clases (5000x10 en este caso). Y por tanto, la salida que nos da la propagación hacia adelante que será de 5000x10 y la $y$ serán directamente comparables. La función de coste nos da una estimación de cómo de poco parecidas son $y$ y $h_\\Theta(X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "98b38176a1863ab27946649c15f6ba77",
     "grade": false,
     "grade_id": "cell-23a91f17841c9ea3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y):\n",
    "    m = X.shape[0]\n",
    "    # Utilizamos las matrices de numpy por facilidad: * es el producto de matrices y np.multiply elemento por elemento\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # desempaquetamos las matrices con los parámetros para cada capa\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    J = -1 / m * np.sum(np.multiply(y, np.log(h)) + np.multiply((1 - y), np.log(1 - h)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10edd2c11ef090bdd14c324639bdedb6",
     "grade": false,
     "grade_id": "cell-d5ba4c2d7d48c96a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Vamos a comprobar que lo  implementado hasta ahora funciona correctamente (también devolvemos los pasos intermedio porque serán útiles más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e5685059cb9c029eb14bb0ca0a4baa3",
     "grade": false,
     "grade_id": "cell-6a8a466c72d04b6d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (10, 26))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración inicial\n",
    "input_size = 400\n",
    "hidden_size = 25\n",
    "num_labels = 10\n",
    "np.random.seed(123456789)\n",
    "\n",
    "# Inicializamos los parámetros de la red aleatoriamente\n",
    "# El tamaño del array es el tamaño de las dos matrices de pesos concatenadas\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "# Podemos desempaquetar los parámetros que acabamos de inicializar igual que lo hacemos en la función de coste\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "# Veamos si los tamaños de las matrices theta1 y theta2 son correctos\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9917f6893400a4b92dba539c8f077697",
     "grade": true,
     "grade_id": "cell-ed08a3bbaa589a12",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 401) (5000, 25) (5000, 26) (5000, 10) (5000, 10)\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "print(a1.shape, z2.shape, a2.shape, z3.shape, h.shape)\n",
    "\n",
    "Test.assertEquals(list(np.round(h[55, :].tolist()[0], 4)), [ 0.4401, 0.5554, 0.3921, 0.4379,0.4063,  0.4987,  0.5222, 0.4887, 0.6124, 0.5376], 'Resultado de la propagación hacia adelante incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b305236879bccd9e10bf60cb8d18d814",
     "grade": false,
     "grade_id": "cell-102dd85cf440491a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Sabiendo que la función de propagación hacia adelante funciona correctamente, veamos si la función de coste también funciona como debe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9450d0fbe7fb475f2f06c31250630476",
     "grade": false,
     "grade_id": "cell-06230cbaf0abb4f2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8223773858037955\n"
     ]
    }
   ],
   "source": [
    "error = cost(params, input_size, hidden_size, num_labels, X, y_onehot)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f088709f49083ac65d23e46722a2415",
     "grade": true,
     "grade_id": "cell-34303285dbc56737",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(round(error, 4), 6.8224, 'Función de coste incorrecta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fea91631374c4d82c3cd6d05baf482d",
     "grade": false,
     "grade_id": "cell-961b9ef5508098e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Función de coste con regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3bed46cca2429583aa0b5580353e8b5c",
     "grade": false,
     "grade_id": "cell-7660c36a4b71b235",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Una vez implementada la función de coste sin regularización, vamos a pasar a la versión regularizada. Realmente el único cambio es que debemos sumar la parte correspondiente a la regularización (la suma de los parámetros al cuadrado sin contar los que corresponden a los bias).\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\bigg[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\bigg] + \\frac{\\lambda}{2m}\\bigg[\\sum_{j=1}^{25}\\sum_{k=1}^{400}(\\Theta_{j,k}^{(1)})^2+\\sum_{j=1}^{10}\\sum_{k=1}^{25}(\\Theta_{j,k}^{(2)})^2\\bigg]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "626a7bff839980727758e02aba343fc2",
     "grade": false,
     "grade_id": "cell-41384dfbbe6cc6e0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def costReg(params, input_size, hidden_size, num_labels, X, y, lambda_reg):\n",
    "    m = X.shape[0]\n",
    "    # Utilizamos las matrices de numpy por facilidad: * es el producto de matrices y np.multiply elemento por elemento\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # desempaquetamos las matrices con los parámetros para cada capa, obtener theta1 y theta2\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    # Añadir a lo implementado anteriormente el término de regularización\n",
    "    # Es decir, la suma de los parámetros al cuadrado sin considerar la primera columna en ninguna de las dos matrices de parámetros\n",
    "    reg = lambda_reg / (2 * m) * (np.sum(np.square(theta1[:, 1:])) + np.sum(np.square(theta2[:, 1:])) )\n",
    "    J = -1 / m * np.sum(np.multiply(y, np.log(h)) + np.multiply((1 - y), np.log(1 - h))) + reg\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "61af351b888975d01952bd7ae90c5f6b",
     "grade": false,
     "grade_id": "cell-0c03b081d0f16e17",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.827724308940754\n"
     ]
    }
   ],
   "source": [
    "# Establecemos el valor de lambda\n",
    "lambda_reg = 1.0\n",
    "error = costReg(params, input_size, hidden_size, num_labels, X, y_onehot, lambda_reg)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "328a043d1087a8ad312839697b4ee164",
     "grade": true,
     "grade_id": "cell-17134a855ecdaa06",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(round(error, 4), 6.8277, 'Función de coste incorrecta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec0e3753f8d8713c9c145bb420a54891",
     "grade": false,
     "grade_id": "cell-6dc41093b9b086ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Propagación hacia atrás - backpropagation\n",
    "A continuación debemos implementar el algoritmo de backprogation (propagación hacia atrás). Esta parte del algoritmo calcula la actualización de los parámetros con el objetivo de reducir el error sobre el conjunto de entrenamiento. \n",
    "\n",
    "En primer lugar necesitamos calcular el gradiente de la función sigmoide que hemos implementado antes:\n",
    "$$ g'(z) = g(z)(1 - g(z))$$\n",
    "\n",
    "**Ten en cuenta que debes aplicar el producto elemento por elemento (con `np.multiply`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "34c0df18e4db719e8851d85906fbfd79",
     "grade": false,
     "grade_id": "cell-dea5b5a8a4287174",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), 1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71d25f0d4007b338c9c560d13166562f",
     "grade": false,
     "grade_id": "cell-98c4cb4723027151",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ahora ya podemos implementar la propagación hacia atrás para calcular los gradientes. Como los cálculos requeridos por backpropagation involucran a todos los calculos realizados en la función de coste, vamos realmente a extender la función de coste que acabamos de implementar para que también calcule la propagación hacia atrás y devuelva el coste y los gradientes (de tal forma que luego podamos usar `minimize`).\n",
    "\n",
    "![Backpropagation](img_backprop.png)\n",
    "\n",
    "**Algoritmo**\n",
    "\n",
    "Inicializamos $\\Delta^{(1)}_{ij}$ y $\\Delta^{(2)}_{ij}$ a 0 (lo utilizamos para calcular el gradiente)\n",
    "\n",
    "Para cada ejemplo $i=0,...,m$\n",
    "1. Calculamos el error en la capa de salida $$\\delta^{(3)} = h_\\Theta(x^{(i)})-y^{(i)}$$ (tener en cuenta que $y$ es un vector en este caso y por tanto tenemos el error en las 10 neuronas de salida).\n",
    "2. Calculamos el error para la capa oculta $\\delta^{(2)}$ propagando el error en la capa de salida $\\delta^{(3)}$:\n",
    "$$\\delta^{(2)}=(\\Theta^{(2)})^T·\\delta^{(3)}.*g'(z^{(2)})$$ \n",
    "Para poder aplicar la fórmula debemos añadir una columna de unos a $z^{(2)}$.\n",
    "3. Sumamos el valor del gradiente en cada caso al acumulador correspondiente\n",
    "$$\\Delta^{(l)}_{ij}=\\Delta^{(l)}_{ij}+\\delta^{(l+1)}(a^{(l)})^T$$\n",
    "Es decir,\n",
    "$$\\Delta^{(1)}_{ij}=\\Delta^{(1)}_{ij}+\\delta^{(2)}(a^{(1)})^T$$ (eliminando el primer elemento de $\\delta^{(2)}$)\n",
    "y\n",
    "$$\\Delta^{(2)}_{ij}=\\Delta^{(2)}_{ij}+\\delta^{(3)}(a^{(2)})^T$$\n",
    "\n",
    "Finalmente, solo debemos calcular los gradientes $D^{(l)}_{ij}$ como\n",
    "$$D^{(l)}_{ij}= \\frac{\\Delta^{(l)}_{ij}}{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "80d13d12e652d16d4d4f746125792ec9",
     "grade": false,
     "grade_id": "cell-75600a7bfd372669",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y):\n",
    "    ###################################################################\n",
    "    # Copiar aquí el código de la función de coste sin regularización #\n",
    "    ###################################################################\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    J = -1 / m * np.sum(np.multiply(y, np.log(h)) + np.multiply((1 - y), np.log(1 - h)))\n",
    "    \n",
    "    ############################\n",
    "    # Comienza Backpropagation #\n",
    "    ############################\n",
    "    # Inicializamos los acumuladores delta1  y delta2 a ceros, con las dismensiones de los theta1 y theta2\n",
    "    # tendrán dimensiones (25, 401) y (10, 26), respectivamente\n",
    "    delta1 = np.zeros((25, 401))\n",
    "    delta2 = np.zeros((10, 26))\n",
    "    \n",
    "    # Aunque podríamos vectorizarlo vamos a hacerlo para cada ejemplo\n",
    "    for t in range(m):\n",
    "        # Obtenemos lo que necesitamos del ejemplo (cálculos obtenidos en la propagación hacia adelante)\n",
    "        # Para usar las fórmulas tal y como aparecen, vamos a coger todos los vectores en forma columna (resahpe(-1,1))\n",
    "        a1t = a1[t,:].reshape(-1, 1)  # (401, 1)\n",
    "        z2t = z2[t,:].reshape(-1, 1)  # (25, 1)\n",
    "        a2t = a2[t,:].reshape(-1, 1)  # (26, 1)\n",
    "        ht = h[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        yt = y[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        \n",
    "        # Calculamos el error en la capa de salida (delta3), almacenar en d3t\n",
    "        d3t = ht - yt\n",
    "        \n",
    "        # Para calcular el error en la capa oculta (delta2) necesitamos añadir un uno al inicio del vector z2\n",
    "        # Crear z2t añadiendo a z2 el 1 \n",
    "        z2t = np.vstack((np.array([1]).reshape(-1, 1), z2t))\n",
    "        \n",
    "        # Calculamos d2 a partir del error de la capa de salida, los parámetros en theta2 y el gradiente de z2t\n",
    "        # Almacenar en d2t\n",
    "        d2t = np.multiply(np.dot(theta2.T, d3t), sigmoid_gradient(z2t))\n",
    "        \n",
    "        # Ya podemos calcular los gradientes a partir de los errores\n",
    "        # Para calcular el gradiente de los theta1, tenemos en cuenta el error en la capa oculta d2\n",
    "        # Acumular el gradiente del ejemplo en delta1 y delta2\n",
    "        delta1 = delta1 + np.dot(d2t[1:], a1t.T)\n",
    "        delta2 = delta2 + np.dot(d3t, a2t.T)\n",
    "    \n",
    "    # Calculamos el gradiente finalmente dividiendo entre el número de ejemplos\n",
    "    delta1 /= m\n",
    "    delta2 /= m\n",
    "    \n",
    "    # Para pasar los gradientes a minimize los ponemos en un vector\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdc62e3df7f77d08917bb20686629da2",
     "grade": false,
     "grade_id": "cell-8cbe111b71566b23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Uno de los aspectos donde hay que tener más cuidado es en la multiplicación de matrices y en sus dimensiones. Además, debes tener en cuenta que la diferencia entre A * B y np.multiply(A, B) es que la primera realiza el producto de matrices y la segunda el producto elemento por elemento. Recuerda que usamos el tipo `matrix` de numpy en vez de `ndarray`.\n",
    "\n",
    "Comprobemos que el resultado es el esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82f91a71d1016d44719d79ee6267ee05",
     "grade": true,
     "grade_id": "cell-45b4f416a9b2b5d1",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8223773858037955 (10285,)\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, X, y_onehot)\n",
    "print(J, grad.shape)\n",
    "Test.assertEquals(list(np.round(grad[np.where(np.abs(grad)>0.0001)[0][:20]], 5)), \n",
    "                  [0.01986, 0.00014, 0.00018, 0.00011, 0.00023, 0.00033, 0.00037, 0.0004, 0.00046, 0.00057, \n",
    "                   0.00067, 0.00082, 0.00104, 0.00111, 0.00079, 0.00034, 0.00011, 0.00031, 0.00063, 0.00093], \n",
    "                  'Gradientes incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc5730d1f59322c1b4673c523a4b3470",
     "grade": false,
     "grade_id": "cell-86ff5121777f2b74",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Propagación hacia atrás - backpropagation - con regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3de63f7baa30558957899173e9bf36a",
     "grade": false,
     "grade_id": "cell-ee2aa314ac5d9e09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ahora queremos añadir la regularización al cáculo del gradiente. En este caso partimos de la función de coste con regularización, realizamos el mismo proceso de backpropagation y solo debemos añadir en el último paso la siguiente modificación:\n",
    "\n",
    "Si $j\\neq0$ entonces\n",
    "$$D^{(l)}_{ij}= \\frac{\\Delta^{(l)}_{ij}}{m} + \\frac{\\lambda}{m}\\Theta_{ij}^{(l)}$$\n",
    "en otro caso\n",
    "$$D^{(l)}_{ij}= \\frac{\\Delta^{(l)}_{ij}}{m}$$\n",
    "\n",
    "Es decir, a las matrices $D^{(l)}_{ij}$ que ya hemos calculado en el paso anterior, en todas las columnas menos a la primera debemos sumarle el término de regularización correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13de2dfa1ff0a03812fa70820ddab751",
     "grade": false,
     "grade_id": "cell-3556dc6db938f279",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def backpropReg(params, input_size, hidden_size, num_labels, X, y, lambda_reg):\n",
    "    ###################################################################\n",
    "    # Copiar aquí el código de la función de coste con regularización #\n",
    "    ###################################################################\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    reg = lambda_reg / (2 * m) * (np.sum(np.square(theta1[:, 1:])) + np.sum(np.square(theta2[:, 1:])) )\n",
    "    J = -1 / m * np.sum(np.multiply(y, np.log(h)) + np.multiply((1 - y), np.log(1 - h))) + reg\n",
    "    \n",
    "     ############################\n",
    "    # Comienza Backpropagation #\n",
    "    ############################\n",
    "    # Inicializamos los acumuladores delta1  y delta2 a ceros, con las dismensiones de los theta1 y theta2\n",
    "    # tendrán dimensiones (25, 401) y (10, 26), respectivamente\n",
    "    delta1 = np.zeros((25, 401))\n",
    "    delta2 = np.zeros((10, 26))\n",
    "    \n",
    "    # Aunque podríamos vectorizarlo vamos a hacerlo para cada ejemplo\n",
    "    for t in range(m):\n",
    "        # Obtenemos lo que necesitamos del ejemplo (cálculos obtenidos en la propagación hacia adelante)\n",
    "        # Para usar las fórmulas tal y como aparecen, vamos a coger todos los vectores en forma columna (resahpe(-1,1))\n",
    "        a1t = a1[t,:].reshape(-1, 1)  # (401, 1)\n",
    "        z2t = z2[t,:].reshape(-1, 1)  # (25, 1)\n",
    "        a2t = a2[t,:].reshape(-1, 1)  # (26, 1)\n",
    "        ht = h[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        yt = y[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        \n",
    "        # Calculamos el error en la capa de salida (delta3), almacenar en d3t\n",
    "        d3t = ht - yt\n",
    "        \n",
    "        # Para calcular el error en la capa oculta (delta2) necesitamos añadir un uno al inicio del vector z2t\n",
    "        # Almacenar en z2t\n",
    "        z2t = np.vstack((np.array([1]).reshape(-1, 1), z2t))\n",
    "        \n",
    "        # Calculamos d2 a partir del error de la capa de salida, los parámetros en theta2 y el gradiente de z2t (guardar en d2t)\n",
    "        d2t = np.multiply(np.dot(theta2.T, d3t), sigmoid_gradient(z2t))\n",
    "        \n",
    "        # Ya podemos calcular los gradientes a partir de los errores\n",
    "        # Para calcular el gradiente de los theta1, tenemos en cuenta el error en la capa oculta d2\n",
    "        # Acumular el gradiente del ejemplo en delta1 y delta2\n",
    "        delta1 = delta1 + np.dot(d2t[1:], a1t.T)\n",
    "        delta2 = delta2 + np.dot(d3t, a2t.T)\n",
    "    \n",
    "    # Calculamos el gradiente finalmente dividiendo entre el número de ejemplos\n",
    "    delta1 /= m\n",
    "    delta2 /= m\n",
    "    \n",
    "    # Añadimos el término de regularización en delta1 y delta2 (no regularizar el bias)\n",
    "    delta1[:, 1:] += lambda_reg / m * theta1[:, 1:]\n",
    "    delta2[:, 1:] += lambda_reg / m * theta2[:, 1:]\n",
    "    \n",
    "    # Para pasar los gradientes a minimize los ponemos en un vector\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2330143440059365417d5fd5ac655e98",
     "grade": true,
     "grade_id": "cell-327e3a5b1ba60cbd",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.827724308940754 (10285,)\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "J, grad = backpropReg(params, input_size, hidden_size, num_labels, X, y_onehot, lambda_reg)\n",
    "print(J, grad.shape)\n",
    "Test.assertEquals(list(np.round(grad[np.where(np.abs(grad)>0.0001)[0][:20]], 5)), \n",
    "                  [0.01986, 0.00015, 0.00016, 0.00013, 0.00022, 0.00033, 0.00036, 0.00039, 0.00048, 0.00057, \n",
    "                   0.00068, 0.00083, 0.00103, 0.00113, 0.00078, 0.00036, 0.00013, 0.00029, 0.00066, 0.00092], \n",
    "                  'Gradientes incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c3336f84ac3904e38ee728a0187ce8bb",
     "grade": false,
     "grade_id": "cell-8c0a67cdcb2f874f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Entrenamiento de la red y clasificación\n",
    "\n",
    "Ahora ya estamos listos para entrenar la red y usarla para hacer predicciones. Para entrenarla, utilizamos el método `minimize`de scipy, indicándole que backpropReg es la función que calcula el coste y los gradientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.3286736770964158\n",
       "     jac: array([ 4.88155821e-05, -1.51082806e-07, -4.21702356e-08, ...,\n",
       "       -5.65653002e-05, -6.00343558e-06,  8.23543779e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 22\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-1.33556857e+00, -7.55414029e-04, -2.10851178e-04, ...,\n",
       "       -2.70057184e+00, -1.77033480e+00,  1.70599386e+00])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Minimizar la función objetivo que acabamos de definir\n",
    "fmin = minimize(fun=backpropReg, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, lambda_reg), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2beccd61823c946edee473c06268e878",
     "grade": false,
     "grade_id": "cell-8fdb1f6727984647",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Lógicamente hemos puesto un límite de iteraciones. Ahora, con el modelo obtenido vamos a tratar de realizar las predicciones para nuestros ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "70529a62182d0f09a072463d06714e82",
     "grade": false,
     "grade_id": "cell-0dfd2c109cdc8098",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [9],\n",
       "        [9],\n",
       "        [9]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desempaquetamos los parámetros obtenidos como resultado del entrenamiento almacenados en fmin.x\n",
    "# Crea las variables theta1 y theta2\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "# Utilizamos los parámetros desempaquetados con la propagación hacia adelante para obtener la predicción para nuestros ejemplos\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "# Finalmente, para obtener la clase para cada ejemplo, buscamos de las diez salidas cual es la más alta\n",
    "# y usamos su índice como valor predicho (utilizar np.argmax con axis=1 que hace precísamente eso).\n",
    "y_pred = np.argmax(h, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ffa9bed0518a09fc3744918e025c8f3",
     "grade": false,
     "grade_id": "cell-51513d62888c3671",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finalmente, podemos calcular la precisión del modelo en entrenamiento para ver cómo de bien está funcionando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a27d96617632636608c270ce4cf94670",
     "grade": true,
     "grade_id": "cell-929faa1c181fc105",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en train: 99.32%\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accTrain = metrics.accuracy_score(y_pred, y)\n",
    "\n",
    "print(\"Precisión en train: {}%\".format(accTrain*100))\n",
    "\n",
    "Test.assertEquals(np.round(accTrain,2), 0.99, 'Precisión incorrecta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1fa026f6a6e11b96109f529047bc061",
     "grade": false,
     "grade_id": "cell-13bcced842c1587d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Tarea adicional\n",
    "El error que obtenemos es muy bajo. ¿Pero qué ejemplos estamos fallando? ¿El ojo humano los diferenciaría? Obtén los ejemplos que se están fallando y píntalos como hemos hecho al principio junto con la clase real del ejemplo y la clase que le asigna la red. ¿Serías capaz de hacerlo mejor que la propia red neuronal?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6db8d2b4124210f6ae06df1e98302c33",
     "grade": true,
     "grade_id": "cell-8b5593932f19d35c",
     "locked": false,
     "points": 8,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 142,  265,  531,  675,  765, 1087, 1408, 1412, 1413, 1440, 1550,\n",
       "       1617, 1701, 1764, 1923, 1959, 1970, 2112, 2171, 2187, 2506, 2556,\n",
       "       3043, 3382, 3515, 3732, 3795, 3895, 4069, 4509, 4593, 4636, 4844,\n",
       "       4863], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallos = np.where(y_pred != y)[0]\n",
    "fallos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 8\n",
    "fig, axes = plt.subplots(fallos.size//n + (fallos.size%n!=0), n, figsize=(20, 20))\n",
    "\n",
    "for i in range(len(fallos)):\n",
    "    index = fallos[i]\n",
    "    img = X[index, :].reshape(20, 20, order='F')\n",
    "    axes[i//n, i%n].imshow(img, cmap=plt.cm.gray)\n",
    "    axes[i//n, i%n].axis('off')\n",
    "    \n",
    "for j in range(i%n+1, n):\n",
    "    axes[i//n, j%n].set_axis_off()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
